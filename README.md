# TELLM  
  
TeLLM is a basic terminal application used to communicate with remotely hosted LLM APIs through an inference API.  
_Currently only supports [fireworks.ai](https://fireworks.ai)._
  
## Usage  

Set the FIREWORKS_API_KEY environment variable.  
Install the dependencies  
Execute assistant.py  

## Feature Ideas  
  
* Markdown print/display in terminal
* Manage conversations/sessions
* Tool use support for the models
* Different inference providers
* Remember information about the user
* Some kind of TUI?
* Proper Python Package structure
